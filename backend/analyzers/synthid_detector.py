"""
synthid_detector.py - Complete AI Image Detector
Uses Gemini 3 model
"""

import os
import google.generativeai as genai
from PIL import Image
import requests
from io import BytesIO
import logging
import json
import re
from typing import Dict

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SynthIDDetector:
    """
    Complete AI Image Detector - uses Gemini 3
    """
    
    def __init__(self, api_key: str = None):
        """Initialize with Gemini API key"""
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        
        if not self.api_key:
            raise ValueError("âŒ GEMINI_API_KEY not found in .env file!")
        
        # Configure Gemini
        genai.configure(api_key=self.api_key)
        
        # Try Gemini 3 models FIRST
        model_names = [
            'gemini-3-flash-preview',      # Gemini 3 Flash (fast)
            'gemini-3-pro-preview',         # Gemini 3 Pro (powerful)
            'gemini-1.5-flash',              # Fallback
            'gemini-1.5-pro',                 # Fallback
            'gemini-pro-vision',               # Last resort
        ]
        
        self.model = None
        self.model_name = None
        
        for model_name in model_names:
            try:
                logger.info(f"Attempting to load model: {model_name}")
                self.model = genai.GenerativeModel(model_name)
                # Test the model
                test = self.model.generate_content("test")
                logger.info(f"âœ… SUCCESS! Using model: {model_name}")
                self.model_name = model_name
                break
            except Exception as e:
                logger.warning(f"âŒ Failed to load {model_name}: {e}")
        
        if not self.model:
            # List available models for debugging
            logger.error("âŒ Could not load any vision model. Available models:")
            try:
                for m in genai.list_models():
                    if 'generateContent' in str(m.supported_generation_methods):
                        logger.info(f"  âœ… {m.name} - supports generateContent")
            except:
                pass
            raise ValueError("No compatible Gemini vision model found")
    
    def analyze_image(self, image_url: str) -> Dict:
        """
        Complete image analysis - AI detection
        """
        logger.info(f"ðŸ” Analyzing image: {image_url[:50]}...")
        
        try:
            # Download the image
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(image_url, timeout=10, headers=headers)
            
            if response.status_code != 200:
                return self._error_result(f"HTTP {response.status_code}")
            
            # Open image
            try:
                img = Image.open(BytesIO(response.content))
                logger.info(f"Image loaded: {img.size} {img.format}")
            except Exception as e:
                return self._error_result(f"Cannot open image: {str(e)}")
            
            # Create comprehensive prompt
            prompt = self._create_full_prompt()
            
            # Send to Gemini
            response = self.model.generate_content([prompt, img])
            
            # Parse the response
            result = self._parse_response(response.text)
            
            # Add model info
            result['model_used'] = self.model_name
            
            if result['is_ai_generated']:
                logger.info(f"âœ… AI DETECTED! Confidence: {result['confidence']}%")
                if result.get('indicators'):
                    logger.info(f"   Indicators: {result['indicators']}")
            else:
                logger.info(f"âŒ No AI detected")
            
            return result
            
        except Exception as e:
            logger.error(f"Error in analyze_image: {e}")
            return self._error_result(str(e))
    
    def _create_full_prompt(self) -> str:
        """
        Complete prompt that checks for AI generation signs
        """
        return """You are an AI image forensic expert. Analyze this image and determine if it was generated by AI or is a real photograph.

Check for these common AI artifacts:
1. HANDS AND FINGERS:
   - Extra or missing fingers
   - Hands that look twisted or unnatural
   - Fingers merging together

2. FACES AND EYES:
   - Eyes that look glassy or dead
   - Asymmetrical facial features
   - Teeth that look weird
   - Skin that looks too smooth/waxy

3. TEXT AND DETAILS:
   - Text that looks garbled or makes no sense
   - Logos or writing that's almost readable but not
   - Repeated patterns that shouldn't repeat
   - Objects that blend into each other

4. LIGHTING AND SHADOWS:
   - Shadows that don't match the light source
   - Lighting that looks unnatural
   - Reflections that don't make sense

5. OVERALL LOOK:
   - Too smooth/perfect (uncanny valley)
   - Dream-like quality
   - Oversaturated or weird colors

Return your analysis in this EXACT JSON format:
{
    "is_ai_generated": true or false,
    "confidence": 0-100,
    "indicators": ["list", "of", "specific", "issues", "found"],
    "explanation": "detailed explanation of your findings"
}

Be thorough but honest. Only mark as AI if you see clear indicators."""
    
    def _parse_response(self, response_text: str) -> Dict:
        """Parse Gemini's response into a clean dictionary"""
        try:
            # Try to find JSON in the response
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            
            if json_match:
                result = json.loads(json_match.group())
                
                return {
                    'is_ai_generated': result.get('is_ai_generated', False),
                    'confidence': result.get('confidence', 0),
                    'indicators': result.get('indicators', []),
                    'explanation': result.get('explanation', 'No explanation provided'),
                    'method': 'gemini_3_analysis'
                }
            else:
                return {
                    'is_ai_generated': 'ai' in response_text.lower() and 'not' not in response_text.lower(),
                    'confidence': 50,
                    'indicators': [],
                    'explanation': response_text[:200],
                    'method': 'fallback'
                }
                
        except Exception as e:
            logger.error(f"Parse error: {e}")
            return self._error_result(f"Failed to parse response")
    
    def _error_result(self, error_msg: str) -> Dict:
        """Return a clean error result"""
        return {
            'is_ai_generated': False,
            'confidence': 0,
            'indicators': [],
            'explanation': f"Error: {error_msg}",
            'method': 'error',
            'error': True
        }