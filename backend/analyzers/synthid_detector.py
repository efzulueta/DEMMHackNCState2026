"""
synthid_detector.py - Complete AI Image Detector
Using Gemini 1.5 Flash (proven to work)
"""

import os
import google.generativeai as genai
from PIL import Image
import requests
from io import BytesIO
import logging
import json
import re
from typing import Dict

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SynthIDDetector:
    """
    Complete AI Image Detector - uses proven working models
    """
    
    def __init__(self, api_key: str = None):
        """Initialize with Gemini API key"""
        self.api_key = api_key or os.getenv('GEMINI_API_KEY')
        
        if not self.api_key:
            raise ValueError("âŒ GEMINI_API_KEY not found in .env file!")
        
        # Configure Gemini
        genai.configure(api_key=self.api_key)
        
        # Try proven working models FIRST (from your successful logs)
        model_names = [
            'gemini-1.5-flash',      # This worked in your logs!
            'gemini-1.5-pro',         # Backup
            'gemini-pro-vision',       # Older but reliable
            'gemini-3-flash-preview',  # Try Gemini 3 as last resort
        ]
        
        self.model = None
        self.model_name = None
        
        for model_name in model_names:
            try:
                logger.info(f"Attempting to load model: {model_name}")
                self.model = genai.GenerativeModel(model_name)
                # Test the model with a simple prompt
                test = self.model.generate_content("test")
                logger.info(f"âœ… SUCCESS! Using model: {model_name}")
                self.model_name = model_name
                return
            except Exception as e:
                logger.warning(f"âŒ Failed to load {model_name}: {e}")
        
        raise ValueError("No compatible Gemini model found")
    
    def analyze_image(self, image_url: str) -> Dict:
        """
        Complete image analysis - AI detection
        """
        logger.info(f"ðŸ” Analyzing image: {image_url[:50]}...")
        
        try:
            # Download the image with proper headers
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            }
            response = requests.get(image_url, timeout=15, headers=headers)
            
            if response.status_code != 200:
                return self._error_result(f"HTTP {response.status_code}")
            
            # Open image
            try:
                img = Image.open(BytesIO(response.content))
                logger.info(f"Image loaded: {img.size} {img.format}")
            except Exception as e:
                return self._error_result(f"Cannot open image: {str(e)}")
            
            # Resize large images to prevent timeout
            max_size = 1024
            if max(img.size) > max_size:
                img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                logger.info(f"Resized to: {img.size}")
            
            # Use the prompt that worked in your logs
            prompt = self._create_full_prompt()
            
            # Send to Gemini
            response = self.model.generate_content([prompt, img])
            
            # Parse the response
            result = self._parse_response(response.text)
            
            # Add model info
            result['model_used'] = self.model_name
            
            if result['is_ai_generated']:
                logger.info(f"âœ… AI DETECTED! Confidence: {result['confidence']}%")
                if result.get('indicators'):
                    logger.info(f"   Indicators: {result['indicators']}")
            else:
                logger.info(f"âŒ No AI detected")
            
            return result
            
        except Exception as e:
            logger.error(f"Error in analyze_image: {e}")
            return self._error_result(str(e))
    
    def _create_full_prompt(self) -> str:
        """
        Complete prompt that checks for AI generation signs
        """
        return """You are an AI image forensic expert. Analyze this image and determine if it was generated by AI or is a real photograph.

Check for these common AI artifacts:

1. HANDS AND FINGERS:
   - Extra or missing fingers
   - Hands that look twisted or unnatural
   - Fingers merging together
   - Impossible hand positions

2. FACES AND EYES:
   - Eyes that look glassy or dead
   - Asymmetrical facial features
   - Teeth that look weird or too many
   - Skin that looks too smooth/waxy
   - Strange expressions or proportions

3. TEXT AND DETAILS:
   - Text that looks garbled or makes no sense
   - Logos or writing that's almost readable but not
   - Repeated patterns that shouldn't repeat
   - Objects that blend into each other
   - Impossible details or structures

4. LIGHTING AND SHADOWS:
   - Shadows that don't match the light source
   - Lighting that looks unnatural
   - Reflections that don't make sense
   - Inconsistent light direction

5. OVERALL LOOK:
   - Too smooth/perfect (uncanny valley)
   - Dream-like quality
   - Oversaturated or weird colors
   - Lack of natural imperfections

Return your analysis in this EXACT JSON format:
{
    "is_ai_generated": true or false,
    "confidence": 0-100,
    "indicators": ["list", "of", "specific", "issues", "found"],
    "explanation": "detailed explanation of your findings"
}

Be thorough but honest. Only mark as AI if you see clear indicators."""
    
    def _parse_response(self, response_text: str) -> Dict:
        """Parse Gemini's response into a clean dictionary"""
        try:
            # Try to find JSON in the response
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            
            if json_match:
                result = json.loads(json_match.group())
                
                return {
                    'is_ai_generated': result.get('is_ai_generated', False),
                    'confidence': result.get('confidence', 0),
                    'indicators': result.get('indicators', []),
                    'explanation': result.get('explanation', 'No explanation provided'),
                    'method': 'gemini_analysis'
                }
            else:
                # If no JSON found, create basic response from text
                return {
                    'is_ai_generated': 'ai' in response_text.lower() and 'not' not in response_text.lower(),
                    'confidence': 50,
                    'indicators': [],
                    'explanation': response_text[:200],
                    'method': 'fallback'
                }
                
        except Exception as e:
            logger.error(f"Parse error: {e}")
            return self._error_result(f"Failed to parse response")
    
    def _error_result(self, error_msg: str) -> Dict:
        """Return a clean error result"""
        return {
            'is_ai_generated': False,
            'confidence': 0,
            'indicators': [],
            'explanation': f"Error: {error_msg}",
            'method': 'error',
            'error': True
        }